{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local search raport\n",
    "\n",
    "≈Åukasz Andryszewski 151930\n",
    "\n",
    "## Qaudratic Assignment Problem (QAP)\n",
    "\n",
    "The tackled problem is NP-hard, meaning there's no polynomial time algorithm that guarantees optimum. The goal of the optimization is:\n",
    "\n",
    "$$ \\min_{\\pi} \\sum_{i=0}^{n}\\sum_{j=0}^{n} a_{ij} \\cdot b_{\\pi_{i}\\pi_{j}}$$\n",
    "\n",
    "The problem can be thought of as assigning some 'departments' to some 'locations'. The $a$ is the flow of communication between the 'departments' and $b$ is a distance matrix between the 'locations'. The $\\pi$ is a permutation, which describes to which 'locations', different 'departments' are assigned. The aim is to minimise the cost of communication between all of the 'departments', by controlling their 'location'.\n",
    "\n",
    "The problem has real world applications, like in the case of the $\\texttt{KraXXx}$ instances. These contain real world data, which was used to plan the Klinikum Regensburg in Germany. Or the $\\texttt{EscXXx}$ instances which \"...stem from an application in computer science, from the testing of self-testable sequential\n",
    "circuits\".\n",
    "\n",
    "### Chosen instances:\n",
    "\n",
    "Instances bigger in size were selected, to limit test the solver. For each type, as described in the QAPLIB description, it was desirable to have it in multiple sizes in order to potentially analyze the impact of the size of instance. It was also important for the instance to have the optimum known.\n",
    "\n",
    "- $\\texttt{Lipa20a}$, $\\texttt{Lipa50a}$ and $\\texttt{Lipa90a}$ examples were chosen because they are generated using the same method, the optimum is known and they are assymetric which makes them somewhat interesting.\n",
    "\n",
    "- $\\texttt{Esc16a}$, $\\texttt{Esc32g}$ and $\\texttt{Esc128}$, because they come from real life problems and are of different sizes.\n",
    "\n",
    "- $\\texttt{tai50b}$, $\\texttt{tai100b}$ and $\\texttt{tai150b}$, because they are all assymetric and generated the same way\n",
    "\n",
    "- $\\texttt{tai64c}$, $\\texttt{tai256c}$ because they 'occur in the generation of grey patterns' and also contain the largest instance\n",
    "\n",
    "## Solver implementation\n",
    "\n",
    "The solver used to analyse the problem was written in C++ and compiled using g++. It can appropriately handle assymetric instances. It implements:\n",
    "\n",
    "- Local search (in steepest and greedy version) - local_search\n",
    "- Random walk - random_walk\n",
    "- Random search - random_seach\n",
    "- a construction Heuristic - heuristic\n",
    "\n",
    "Construction heuristic calculates value of adding a new assignment at the end. Then the best assignment is kept. An additional boolean array is used to determine if a 'location' is already assigned. Additionally the first assignment is random to make the heuristic non-deterministic.\n",
    "\n",
    "The program is used as follows:\n",
    "\n",
    "```bat\n",
    "bio_solver.exe (instance:str) (solver_name:std) (repetitions:int) (solver_args...)\n",
    "```\n",
    "\n",
    "Local search takes ```steepest``` or ```greedy``` as an argument. Random walk and random search take ```duration``` in nanoseconds as an argument.\n",
    "\n",
    "The program outputs:\n",
    "\n",
    "- instance_name instance_size optimal_value\n",
    "- optimal_solution\n",
    "- number_of_repetitions\n",
    "Then repetitions of:\n",
    "- initial_solution\n",
    "- final_solution\n",
    "- starting_value final_value\n",
    "- evaluations steps execution_time\n",
    "\n",
    "```run_all.bat``` program takes instances as an argument and then runs all the solvers on these instances, with predefined number of repetitions. The execution time for RS and RW is taken as an average of execution times of greedy and steepest local search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighbourhood\n",
    "\n",
    "The defining operator in local search is how the neighbourhood of a solution is defined. Local search implemented hear used the 2-OPT neighbourhood. For this operator the size can be defined as:\n",
    "\n",
    "$$ N = \\dfrac{n^2 - n}{2} $$\n",
    "\n",
    "Which can be thought of as the upper triangular part of a square matrix. The neighbourhood is initialized, for each instance of local search, by creating every combination of two positions. Then its shuffled. A random offset is initialized to help with the randomization of ordering, whilst not spending much time on additional reshuffling. This is especially important for greedy, because the first found improvement is selected in each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from util import pandify\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_over(start_val, final_val, opt):\n",
    "    # assuming minimization of objective\n",
    "    # to be minimized\n",
    "    return (start_val - final_val) / opt\n",
    "\n",
    "def quality_to_opt(final_val, opt):\n",
    "    return quality_over(final_val,opt,opt)\n",
    "\n",
    "def similarity(sol1, sol2):\n",
    "    return np.mean(sol1==sol2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [\"lipa20a\",\"lipa50a\",\"lipa90a\",\"esc16a\",\"esc32g\",\"esc128\",\"tai50b\",\"tai100b\", \"tai150b\",\"tai64c\",\"tai256c\"]\n",
    "print(*instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instances = list(\"esc128 tai256c wil100 tho150 lipa90b chr25a bur26a rou12\".split())\n",
    "solvers = [\"ls_greedy\", \"ls_steepest\", \"rs\", \"rw\", \"heuristic\"]\n",
    "shorter_solvers = [\"G\",\"S\",\"RS\",\"RW\", \"H\"]\n",
    "full_solvers = [\"local_search_greedy\",\"local_search_steepest\",\"random_search\",\"random_walk\", \"heuristic\"]\n",
    "solver_map = {short:full for short,full in zip(solvers,full_solvers)}\n",
    "solver_to_short_map = {full:short for short,full in zip(shorter_solvers,full_solvers)}\n",
    "colors = [\"seagreen\", \"mediumblue\", \"red\", \"orange\", \"hotpink\"]\n",
    "color_map = {solver:color for solver,color in zip(colors, full_solvers)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandify(instances,solvers,solver_map)\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time was measured in nanoseconds with the C++ ```chrono``` library using a ```high_resolution_clock```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flierprops = dict(marker='o', markerfacecolor='black', markersize=5,markeredgecolor='none',alpha=0.2)\n",
    "X = data.pivot(columns=[\"instance\",\"solver\"], index=\"repetition\")[\"time\"]\n",
    "fig, axs = plt.subplots(ncols=3,nrows=4,layout=\"tight\",sharex=True,sharey='row')\n",
    "fig.set_size_inches(10,10)\n",
    "fig.supylabel(\"Running time\")\n",
    "for instance, ax in zip(instances,fig.get_axes()):\n",
    "    ax.set_title(instance)\n",
    "    vplot = ax.violinplot(X[instance],showextrema=False)\n",
    "    bplot = ax.boxplot(X[instance],widths=0.2,medianprops=dict(color=\"black\"),flierprops=flierprops)\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True,which=\"major\",ls='-')\n",
    "    ax.grid(True,which=\"minor\",ls='dotted')\n",
    "    ax.yaxis.set_major_locator(mpl.ticker.LogLocator())\n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda x, pos: f\"{x/1e6:.2f} ms\"))\n",
    "    ax.set_xticks(np.arange(len(solvers))+1,shorter_solvers[:len(solvers)])\n",
    "    for vp, color in zip(vplot[\"bodies\"],colors):\n",
    "        vp.set_color(color)\n",
    "    ax.set_facecolor(\"whitesmoke\")\n",
    "fig.delaxes(axs[-1, -1])\n",
    "axs[-2,-1].xaxis.set_tick_params(labelbottom=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out steepest is slower than greedy on every tested instance. The running times of random searche and random walk are identical in each repetition. The chosen duration of the algorithms was the average between mean running times of both local searches. As expected the construction heuristic was by far the fastest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality\n",
    "\n",
    "The quality is measured as a relative gap according to the following formula:\n",
    "\n",
    "$$ Q(v_z) = \\dfrac{v_z-v_o}{v_o} = \\dfrac{v_z}{v_o} - 1$$\n",
    "\n",
    "where $v_z$ is the solution value and $v_o$ are the value of the optimum. In describes the distance to the optimum relative to it. This way it is also better comparable between instances. Lower values are more desirable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.assign(quality=lambda df: quality_to_opt(df.final_value,df.optimal_value)).pivot(columns=[\"instance\",\"solver\"], index=\"repetition\")[\"quality\"]\n",
    "X = X.fillna(X.max())\n",
    "fig, axs = plt.subplots(nrows=4,ncols=3,layout=\"tight\",sharex=True)\n",
    "fig.set_size_inches(10,10)\n",
    "fig.supylabel(\"Quality\")\n",
    "for instance, ax in zip(instances,fig.get_axes()):\n",
    "    ax.set_title(instance)\n",
    "    vplot = ax.violinplot(X[instance],showextrema=False)\n",
    "    bplot = ax.boxplot(X[instance],widths=0.2,medianprops=dict(color=\"black\"),flierprops=flierprops)\n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "    ax.set_xticks(np.arange(len(solvers))+1,shorter_solvers[:len(solvers)])\n",
    "    for vp, color in zip(vplot[\"bodies\"],colors):\n",
    "        vp.set_color(color)\n",
    "    ax.set_facecolor(\"whitesmoke\")\n",
    "    ax.grid()\n",
    "fig.delaxes(axs[-1, -1])\n",
    "axs[-2,-1].xaxis.set_tick_params(labelbottom=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the random walk and random search usually have the biggest variances when it comes to the values of the solutions. However in some cases the heuristic performed worse than them. Both local searches had very similar performances and similar distributions, although greedy seems to be slightly better. For a few instances, like $\\texttt{esc32g}$ the quality of the heuristic reaches $0\\%$, which means it achieves the optimal value. This could suggest that these instances may be trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency of algorithms\n",
    "\n",
    "The quality over time is measured as difference of relative gaps between the initial and final solution int relation to the optimum:\n",
    "\n",
    "$$ V(v_i,v_z,t) = \\dfrac{Q(v_i)-Q(v_z)}{t} = \\dfrac{(v_i-v_o)-(v_z-v_o)}{v_ot} = \\dfrac{v_i-v_z}{v_ot}$$\n",
    "\n",
    "where $v_z$ is the solution value and $v_o$ are the value of the optimum. Intuitively it can be though of as 'speed' of the algorithm - how much it improves the initial solution over some time, relative to optima. Higher values are more desirable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = data.assign(quality=lambda df: quality_over(df.initial_value,df.final_value,df.optimal_value)).assign(q_over_t=lambda df: df.quality/df.time)\n",
    "X = X_raw.pivot(columns=[\"instance\",\"solver\"], index=\"repetition\")[\"q_over_t\"]\n",
    "fig, axs = plt.subplots(nrows=4,ncols=3,layout=\"tight\",sharex=True,sharey='row')\n",
    "fig.set_size_inches(10,10)\n",
    "fig.supylabel(\"Quality over time\")\n",
    "for instance, ax in zip(instances,fig.get_axes()):\n",
    "    ax.set_title(instance)\n",
    "    vplot = ax.violinplot(X[instance],showextrema=False)\n",
    "    bplot = ax.boxplot(X[instance],widths=0.2,medianprops=dict(color=\"black\"),flierprops=flierprops)\n",
    "    ax.set_xticks(np.arange(len(solvers))+1,shorter_solvers[:len(solvers)])\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True,which=\"major\",ls='-')\n",
    "    ax.grid(True,which=\"minor\",ls='dotted')\n",
    "    ax.yaxis.set_major_locator(mpl.ticker.LogLocator())\n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda x, pos: f\"{x*100:.0e} %/ns\"))\n",
    "    # ax.xaxis.set_major_locator(mpl.ticker.FixedLocator(np.arange(1,len(selected)+1)))\n",
    "    # ax.set_xticklabels(shorter_solvers)\n",
    "    for vp, color in zip(vplot[\"bodies\"],colors):\n",
    "        vp.set_color(color)\n",
    "    ax.set_facecolor(\"whitesmoke\")\n",
    "    ax.grid()\n",
    "fig.delaxes(axs[-1, -1])\n",
    "axs[-2,-1].xaxis.set_tick_params(labelbottom=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although greedy and steepest achieve similar qualities, because greedy is much faster, it achieves much better efficiency overall. Actually, in effciency steepest performs similarily to random search and random walk. In some cases the heuristic, when compared to a random initial solution, produces a worse solution. This cannot be exactly visualized on a logarithm scale, because it reaches negative values. It can be seen on the table below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw[X_raw.solver == \"heuristic\"].pivot(columns=\"instance\",index=\"repetition\")[\"q_over_t\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of iterations of Local Searches\n",
    "\n",
    "Here the number of iterations performed by local searches are compared. Each iteration is defined as a single move to a neighbour. For steepest the entire neighbourhood is checked and the one giving the best improvement is performed. For greedy the first found improving move is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = full_solvers[:2]\n",
    "mask_ls = data[\"solver\"].isin(selected)\n",
    "X = data[mask_ls].pivot(columns=[\"instance\",\"solver\"], index=\"repetition\")[\"iterations\"]\n",
    "fig, axs = plt.subplots(nrows=4,ncols=3,layout=\"tight\",sharex=True)\n",
    "fig.set_size_inches(10,18)\n",
    "fig.supylabel(\"Iterations\")\n",
    "for instance, ax in zip(instances,fig.get_axes()):\n",
    "    ax.set_title(instance)\n",
    "    vplot = ax.violinplot(X[instance],showextrema=False)\n",
    "    bplot = ax.boxplot(X[instance],widths=0.2,medianprops=dict(color=\"black\"))\n",
    "    #ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda x, pos: f\"{x*100:.3e} %/ns\"))\n",
    "    ax.set_xticks(np.arange(len(selected))+1,shorter_solvers[:len(selected)])\n",
    "    for vp, color in zip(vplot[\"bodies\"],colors[:2]):\n",
    "        vp.set_color(color)\n",
    "    ax.set_facecolor(\"whitesmoke\")\n",
    "    ax.grid()\n",
    "fig.delaxes(axs[-1, -1])\n",
    "axs[-2,-1].xaxis.set_tick_params(labelbottom=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected greedy peforms more iterations of local search, as it does not check the entire neighbourhood. Because of that it does not converge as quickly as steepest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of evaluations\n",
    "\n",
    "An evaluation is counted each time an algorithm either evaluates an entire solution or if an algorithm performs a partial evaluation (calculating the delta of a swap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected = full_solvers[:-1]\n",
    "# mask_GSRSRW = data[\"solver\"].isin(selected)\n",
    "X = data.pivot(columns=[\"instance\",\"solver\"], index=\"repetition\")[\"evaluations\"]\n",
    "fig, axs = plt.subplots(nrows=4,ncols=3,layout=\"tight\",sharex=True)\n",
    "fig.set_size_inches(10,10)\n",
    "fig.supylabel(\"Evaluations\")\n",
    "for instance, ax in zip(instances,fig.get_axes()):\n",
    "    ax.set_title(instance)\n",
    "    vplot = ax.violinplot(X[instance],showextrema=False)\n",
    "    bplot = ax.boxplot(X[instance],widths=0.2,medianprops=dict(color=\"black\"))\n",
    "    #ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda x, pos: f\"{x*100:.3e} %/ns\"))\n",
    "    ax.set_xticks(np.arange(len(shorter_solvers))+1,shorter_solvers)\n",
    "    for vp, color in zip(vplot[\"bodies\"],colors):\n",
    "        vp.set_color(color)\n",
    "    ax.set_facecolor(\"whitesmoke\")\n",
    "    ax.grid()\n",
    "fig.delaxes(axs[-1, -1])\n",
    "axs[-2,-1].xaxis.set_tick_params(labelbottom=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite steepest performing more iterations, it performs less evaluations than steepest. This is exactly because it does not check the entire neighbourhood. It is also expected for random walk to perform more iterations than random search. As these are run for the same amount of time and random walk simply peforms much less in a single 'iteration' compared to random search, it is able to evaluate more solutions. In some cases like $\\texttt{Esc32g}$ the heuristic performs more evaluations than random search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality of initial vs final solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dependence between the initial quality of solution and final quality for local searches is checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[mask_ls].assign(\n",
    "    quality_fin=lambda df: quality_to_opt(df.final_value,df.optimal_value)\n",
    "    ).assign(\n",
    "    quality_start=lambda df: quality_to_opt(df.initial_value,df.optimal_value)\n",
    "    ).pivot(columns=[\"instance\",\"solver\"], index=\"repetition\")\n",
    "corr_data = {col:[] for col in [\"instance\",\"solver\",\"correlation\"]}\n",
    "fig, axs = plt.subplots(nrows=4,ncols=3,layout=\"constrained\")\n",
    "fig.set_size_inches(10,10)\n",
    "fig.supxlabel(\"Initial quality\")\n",
    "fig.supylabel(\"Final quality\")\n",
    "for instance, ax in zip(instances, fig.get_axes()):\n",
    "    ax.set_title(instance)\n",
    "    for solver, color in zip(full_solvers[:2], colors):\n",
    "        x = X[\"quality_start\"][instance][solver]\n",
    "        y = X[\"quality_fin\"][instance][solver]\n",
    "        ax.scatter(x, y, s=3, label=solver_to_short_map[solver],color=color)\n",
    "        corr = np.corrcoef(x,y)[0,1]\n",
    "        corr_data[\"instance\"].append(instance)\n",
    "        corr_data[\"solver\"].append(solver)\n",
    "        corr_data[\"correlation\"].append(corr)\n",
    "        #ax.text(0.9,0.1,f\"{corr:2f}\",transform=ax.transAxes)\n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "    ax.xaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "    #ax.tick_params(axis=\"x\", labelrotation=15)\n",
    "    ax.grid()\n",
    "    ax.set_facecolor(\"whitesmoke\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower right')\n",
    "fig.delaxes(axs[-1, -1])\n",
    "plt.show()\n",
    "corr_data = pd.DataFrame.from_dict(corr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally correlation between the final and initial solution value is presented. The exact measure used is the Pearson Correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data.pivot(columns=\"instance\",index=\"solver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be expected that better initial solutions would produce better final solutions, by the possibility of being placed in a better region of the solution space. However there is seemingly no significant correlation between the quality of initial solution and the quality of the final solution, at least for the selected instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-random start local search\n",
    "\n",
    "In this section the 300 repetitions of local searches are treated as a single multi-random start local search. It works similarily to random search but each solution in the restart is a local optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[mask_ls].assign(quality=lambda df: quality_to_opt(df.final_value,df.optimal_value)).pivot(columns=[\"instance\",\"solver\"], index=\"repetition\")[\"quality\"]\n",
    "best = X.cummin()\n",
    "mean = X.expanding().mean()\n",
    "std = X.expanding().std().fillna(0)\n",
    "fig, axs = plt.subplots(nrows=4,ncols=3,layout=\"constrained\",sharex=True)\n",
    "fig.set_size_inches(10,10)\n",
    "fig.supxlabel(\"Repetitions\")\n",
    "fig.supylabel(\"Quality\")\n",
    "for instance, ax in zip(instances, fig.get_axes()):\n",
    "    ax.set_title(instance)\n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "    for solver, color in zip(full_solvers[:2], colors):\n",
    "        u = mean[instance][solver]\n",
    "        ro = std[instance][solver]\n",
    "        ax.plot(best[instance][solver],label=solver_to_short_map[solver]+\" best\",color=color)\n",
    "        ax.plot(u,'--',label=solver_to_short_map[solver]+\" mean\",color=color)\n",
    "        ax.fill_between(np.arange(len(u)),u+ro,(u-ro).clip(0), label=solver_to_short_map[solver]+\" std\",alpha=0.1,color=color)\n",
    "    ax.grid()\n",
    "    ax.set_facecolor(\"whitesmoke\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower right',ncols=2)\n",
    "fig.delaxes(axs[-1, -1])\n",
    "axs[-2,-1].xaxis.set_tick_params(labelbottom=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is value to be gained from running the local search algorithm multiple times. However the exact number of steps is highly dependent on the instance, as it is an additional parameter. For most of the selected instances it seems $100$ repetitions is enough, as the algorithm usually flatlines. The mean stabilizes and stays roughly the same. Standard deviation is also stable and its value ultimately depends on the instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity of local optimas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity between instances is measured as the inverse of Hamming distance:\n",
    "\n",
    "$$ {Sim}(x_1, x_2) = 1 - H(x_1,x_2) = 1 - \\dfrac{\\sum_{i=0}^n \\begin{cases} 1 & \\text{if $x_1[i]$ $\\neq$ $x_2[i]$} \\\\ 0 & {otherwise}\\end{cases} }{n}$$\n",
    "\n",
    "This measure seems appropriate for the nature of the problem as the position of a solution $x$ describes the department, while the index at that position describes to which location that department is assigned.\n",
    "\n",
    "The similarities are calculated between all local optima and then averaged, as well as between the local optimum and global optimum.\n",
    "\n",
    "The selected instances are $\\texttt{Lipa90a}$ and $\\texttt{tai100b}$ as the heuristic performs badly on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = [\"lipa20a\",\"lipa90a\",\"esc16a\", \"tai100b\"]\n",
    "selected = full_solvers[:2]\n",
    "to = [\"optimal_solution\",\"final_solution\"]\n",
    "to_titles = [\"Wrt optimum\", \"Wrt eachother\"]\n",
    "to_map = {wrt:title for wrt,title in zip(to,to_titles)}\n",
    "X = data[data[\"repetition\"]<100].assign(\n",
    "    quality=lambda df: quality_over(df.initial_value,df.final_value,df.optimal_value)\n",
    "    ).pivot(columns=[\"instance\",\"solver\"], index=\"repetition\")[to+[\"quality\"]]\n",
    "fig, ax = plt.subplots(nrows=4,ncols=2,layout=\"constrained\")\n",
    "fig.set_size_inches(6,12)\n",
    "for (instance, wrt), ax in zip(product(subset,to),fig.get_axes()):\n",
    "    for solver, color in zip(selected,colors):\n",
    "        y = np.array(list(map(lambda sols: similarity(*sols),product(X[wrt][instance][solver],X[\"final_solution\"][instance][solver]))))\n",
    "        n = np.ceil(np.sqrt(y.shape[0])).astype(int)\n",
    "        y = y.reshape((n,n))\n",
    "        np.fill_diagonal(y,0)\n",
    "        mean_y = (y.mean(0))*(n/(n-1))\n",
    "        x = X[\"quality\"][instance][solver]\n",
    "        ax.scatter(x,mean_y,label=solver_to_short_map[solver],color=color,s=4)\n",
    "        if wrt == to[1]:\n",
    "            np.fill_diagonal(y,mean_y)\n",
    "            std_y = y.std(0)*np.sqrt((n)/(n-1)) \n",
    "            ax.errorbar(x,mean_y,std_y,color=color,linestyle=\"none\",marker=\"none\",alpha=0.1)\n",
    "\n",
    "        ax.xaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "        ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "        ax.set_title(to_map[wrt]+\" in \"+instance)\n",
    "        ax.grid(True)\n",
    "        ax.set_facecolor(\"whitesmoke\")\n",
    "fig.supxlabel(\"Quality\")\n",
    "fig.supylabel(\"Similarity\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='outside lower right',ncols=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the problem is globally convex, the expectation is that locally optimal solutions are very similar to eachother. However the similarity is low overall, which can stem from how the nature hamming distance and the size of the instances. Simply speaking, high values are not easy to achieve, even on the smaller instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Overall it was quite suprising to see that the greedy version of local search performed better than the steepest, as I have not seen that often in practice. Althought the final quality was similar, the greedy version was much more efficient. In cases of instances like $\\texttt{Esc32g}$ the heuristic was able to find the optimum along with local searches, as well as competing solutions for instances like $\\texttt{Tai256c}$. \n",
    "\n",
    "No significant correlation between the quality of initial solution and final solution in local searches was found. No significant relation between the similarity and the final quality was found, but this could be partly due to how similarity is calculated.\n",
    "\n",
    "Lastly there is value to be gained from running local search multiple times from different starting locations. After around 100 repetitions, which depends on the instance, the algorithm improves after which it stagnates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difficulties\n",
    "\n",
    "Coming up with an appropriate construction heuristic is not easy as it depends on the problem. In this case its not entirely intuitive on how to do it. The final solution is one that could probably be implemented for most problems, but does not imply good performance. In comparison a heuristic for TSP would add the closest city each time, which in a way is very similar to this solution!\n",
    "\n",
    "There were some difficulties in how to properly pass the specific arguments to the solvers in the program. Finally it was achieved by implementing a ```Experiment class``` which first parses all command lines arguments and then using a ```switch```, launches the appropriate solver with its arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduced improvements\n",
    "\n",
    "Initially the heuristic evaluated the whole incomplete solution. The improvement was to just evaluate assignment of the last 'location'. This was it was much faster, as one would expect for a construction heuristic, while not changing the final result. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
